#!/usr/local/bin/python3

from decouple import config
import helpers.bucket_utilities as bu
import helpers.file_utilities as fu
from pathlib import Path
import argparse
import sys
import json

BUCKET_NAME = config("BUCKET_NAME", default="data-ingest-bk")
LOGGING_BUCKET_NAME = config("LOGGING_BUCKET_NAME", default="logging-bktasks")

def bucket_upload(args):

    lg = fu.StandardLogger.get_instance(arg_parser.prog)
    if args.clear_log:
        lg.clear_log()
    lg.lp_info("LOGGER OPENED")
    try:
        header_row = int(args.header_row)
    except ValueError:
        lg.lp_error(f'Invalid --header-row argument. Expected integer-like')
        sys.exit()

    lg.lp_info(f'JOB STARTING')
    path = Path(args.file_name)

    def args_d_parse_(destination_folder):
        if destination_folder=="/":
            return ""
        elif destination_folder[-1]!="/":
            destination_folder += "/"
        return destination_folder
    
    def preview_or_action(preview: bool, source, destination, **action) -> None:
        lg.lp_info(f'From source {source} to destination {BUCKET_NAME}/{destination}')
        if preview:
            lg.lp_info(f'Preview only. No files uploaded.')
        else:
            lg.lp_info(f'Uploading files.')
            bu.upload_(
                destination_blob_name=action['destination_blob_name'],
                source_object=action['source_object'],
                bucket_name=action['bucket_name']
                )
            if action['common_log']:
                lg.lp_info(f'Uploading common log')
                bu.common_log_("bucket_upload", f'{args.file_name} as {file_type}')

    if not (path.is_file() or path.is_dir()):
        lg.lp_error(f'INVALID FILE: -f/--file-name {args.file_name}')
        sys.exit()
    if path.is_file():
        lg.lp_info(f'Opening file {args.file_name}')
        file_stem = path.stem
        file_destination = f'{args_d_parse_(args.destination_folder)}{file_stem}'
        file_type = path.suffix.replace(".", "")
        if args.to_json:
            lg.lp_info(f'Converting {file_type} to json')
            if file_type=="csv":
                # TODO: no header row
                data = fu.preproc_csv(args.file_name, header_row)
            source_object = {
                "type" : "string",
                "data" : json.dumps(data)
            }
            file_type = "json"
        else: # upload file as is
            source_object = {
                "type" : "file",
                "data" : args.file_name
            }
        preview_or_action(
            preview=args.preview,
            source=args.file_name,
            destination=file_destination,
            destination_blob_name=bu.blob_name_(file_destination, args.batch_id, file_type),
            source_object=source_object,
            bucket_name=args.bucket,
            common_log=True
            )
    elif path.is_dir(): # folder
        lg.lp_info(f'Scanning contents of directory {args.file_name}')
        for p in path.rglob("*"):
            child_source_path = str(p)
            destination_folder = args_d_parse_(args.destination_folder)
            child_destination_path = child_source_path.replace(f'{args.file_name}/', "")
            child_destination_path = f'{destination_folder}{child_destination_path}'
            source_object = {
                "type" : "file",
                "data" : child_source_path
            }
            preview_or_action(
                preview=args.preview,
                source=child_source_path,
                destination=child_destination_path,
                destination_blob_name=child_destination_path,
                source_object=source_object,
                bucket_name=args.bucket,
                common_log=False
            )
        # perform a final common log action after loop
        if not args.preview:
            lg.lp_info(f'Uploading common log')
            bu.common_log_("bucket_upload", f'Uploaded all files from path walk at {args.file_name}')        
    else: # not valid?
        lg.lp_error(f'{FileNotFoundError(args.file_name)}')

    lg.lp_info(f'JOB FINISHED')

arg_parser = argparse.ArgumentParser(
    prog = "BucketUpload",
    description = "Convenience CLI Application For Uploading Files to Cloud Storage",
    epilog = "See Also bucket_downLoad -h"
)
arg_parser.add_argument("-f", "--file-name", required=True, help="File or folder to upload. Supported types: csv, json, txt")
arg_parser.add_argument("-b", "--bucket", default=BUCKET_NAME, help="Destination bucket")
arg_parser.add_argument("-d", "--destination-folder", default="/")
arg_parser.add_argument("-g", "--logging-bucket", default=LOGGING_BUCKET_NAME, help="Logging bucket")
arg_parser.add_argument("-p", "--preview", action="store_true", help="Preview file destinations")
arg_parser.add_argument(
    "-v", "--version",
    action='version',
    version='1.0.0'
)
arg_parser.add_argument(
    "-c", "--clear-log",
    action="store_true",
    help="Clear previous log?"
)
arg_parser.add_argument(
    "-j", "--to-json",
    action="store_true",
    help="Upload object as json?"
)
arg_parser.add_argument(
    "--header-row",
    default="1",
    help="Which row contains headers. If no headers in file, set 0 and require --headers"
)
arg_parser.add_argument(
    "--headers",
    default="1",
    help="Csv file has headers?"
)
arg_parser.add_argument(
    "--batch-id",
    default="1",
    help="Batch id for upload"
)

arg_parser.set_defaults(func=bucket_upload)

if __name__=="__main__":
    args = arg_parser.parse_args()
    args.func(args)
